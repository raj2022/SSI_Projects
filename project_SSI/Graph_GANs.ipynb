{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9becf8a",
   "metadata": {},
   "source": [
    "**Task:-** \n",
    "\n",
    "EF-2: Try to make generative model of jet images, using a AUC of a discriminator to distinguish Generative model data / real data as metric\n",
    "\n",
    "From https://github.com/makagan/SSI_Projects/blob/main/jet_notebooks/1.LHCJetDatasetExploration.ipynbfrom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e73448",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the files\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e2292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']\n"
     ]
    }
   ],
   "source": [
    " # Data already downloaded \n",
    "# let's open the file\n",
    "fileIN = '../jet_notebooks/Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5'\n",
    "f = h5py.File(fileIN)\n",
    "# and see what it contains\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fb77dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'j_ptfrac' b'j_pt' b'j_eta' b'j_mass' b'j_tau1_b1' b'j_tau2_b1'\n",
      " b'j_tau3_b1' b'j_tau1_b2' b'j_tau2_b2' b'j_tau3_b2' b'j_tau32_b1'\n",
      " b'j_tau32_b2' b'j_zlogz' b'j_c1_b0' b'j_c1_b1' b'j_c1_b2' b'j_c2_b1'\n",
      " b'j_c2_b2' b'j_d2_b1' b'j_d2_b2' b'j_d2_a1_b1' b'j_d2_a1_b2' b'j_m2_b1'\n",
      " b'j_m2_b2' b'j_n2_b1' b'j_n2_b2' b'j_tau1_b1_mmdt' b'j_tau2_b1_mmdt'\n",
      " b'j_tau3_b1_mmdt' b'j_tau1_b2_mmdt' b'j_tau2_b2_mmdt' b'j_tau3_b2_mmdt'\n",
      " b'j_tau32_b1_mmdt' b'j_tau32_b2_mmdt' b'j_c1_b0_mmdt' b'j_c1_b1_mmdt'\n",
      " b'j_c1_b2_mmdt' b'j_c2_b1_mmdt' b'j_c2_b2_mmdt' b'j_d2_b1_mmdt'\n",
      " b'j_d2_b2_mmdt' b'j_d2_a1_b1_mmdt' b'j_d2_a1_b2_mmdt' b'j_m2_b1_mmdt'\n",
      " b'j_m2_b2_mmdt' b'j_n2_b1_mmdt' b'j_n2_b2_mmdt' b'j_mass_trim'\n",
      " b'j_mass_mmdt' b'j_mass_prun' b'j_mass_sdb2' b'j_mass_sdm1'\n",
      " b'j_multiplicity' b'j_g' b'j_q' b'j_w' b'j_z' b'j_t' b'j_undef']\n"
     ]
    }
   ],
   "source": [
    "# These are the quantities we are dealing with\n",
    "featurenames = f.get('jetFeatureNames')\n",
    "print(featurenames[:])\n",
    "# the b is due to the byte vs utf-8 encoding of the strings in the dataset\n",
    "# just ignore them for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7592936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"jetImage\": shape (10000, 100, 100), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(f.get('jetImage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f94aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(10000, 5)\n",
      "First five entries:\n",
      "[1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0.]\n",
      "Last 5 entries:\n",
      "[0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "jet_data = np.array(f.get('jets'))\n",
    "target = jet_data[:,-6:-1]\n",
    "# shape of the dataset\n",
    "print(\"Dataset shape:\")\n",
    "print(target.shape)\n",
    "print(\"First five entries:\")\n",
    "for i in range(5):\n",
    "    print(target[i])\n",
    "print(\"Last 5 entries:\")\n",
    "for i in range(-5,0):\n",
    "    print(target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa02526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 53)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(jet_data[:,:-6])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4969dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = input_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index], 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)\n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41036653",
   "metadata": {},
   "source": [
    "# The particle-list dataset\n",
    "In this case, we look at the particle-related features that we have stored for each jet constituent. The structure of the dataset is similar to that of the physics-motivated features, except for the fact that we have now a double-index dataset: (jet index, particle index). The list is cut at 100 constituents /jet. If less are found, the dataset is completed filling it with 0s (zero padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca54a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'j1_px' b'j1_py' b'j1_pz' b'j1_e' b'j1_erel' b'j1_pt' b'j1_ptrel'\n",
      " b'j1_eta' b'j1_etarel' b'j1_etarot' b'j1_phi' b'j1_phirel' b'j1_phirot'\n",
      " b'j1_deltaR' b'j1_costheta' b'j1_costhetarel' b'j1_pdgid']\n"
     ]
    }
   ],
   "source": [
    "p_featurenames = f.get(\"particleFeatureNames\")\n",
    "print(p_featurenames[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c318ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "p_data = f.get(\"jetConstituentList\")\n",
    "print(p_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bfa8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot_p(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        my_data = input_data[:,:,feature_index]\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = my_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index].flatten(), 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)  \n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324d8a4",
   "metadata": {},
   "source": [
    "## Generative model of jet images with AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b337846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing keras and related modules\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664edb7",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab6850",
   "metadata": {},
   "source": [
    "\n",
    "Using the jet image dataset, you can adapt the Graph GAN architecture to generate graph-structured data. Since the jet image dataset isn't inherently graph-structured, we can represent each jet image as a graph using a simplified approach. Here's how you could do it:\n",
    "\n",
    "1. **Convert Jet Images to Graphs:** Each jet image can be represented as a graph, where the nodes represent pixels, and edges connect neighboring pixels. You can create adjacency matrices for each image by considering the pixel intensities as edge weights.\n",
    "\n",
    "2. **Graph GAN Architecture:** The architecture remains similar, but instead of nodes and features, you're dealing with pixels and intensities. The generator takes random noise as input and generates adjacency matrices for the graphs. The discriminator evaluates whether a given adjacency matrix represents a real or generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92858485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Assuming you have jet images in a numpy array 'jet_images'\n",
    "# Normalize the pixel values between 0 and 1\n",
    "jet_images = np.array(f.get('jetImage')).astype('float32') / 255.0\n",
    "num_images, image_size, _ = jet_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f255da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert jet images to adjacency matrices (simplified approach)\n",
    "adj_matrices = []\n",
    "for i in range(num_images):\n",
    "    image = jet_images[i].reshape(-1)  # Flatten image to 1D array\n",
    "    adjacency_matrix = np.outer(image, image)  # Create adjacency matrix\n",
    "    adj_matrices.append(adjacency_matrix)\n",
    "adj_matrices = np.array(adj_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bda6493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (10000, 100, 100)\n",
      "image_size is, 100\n"
     ]
    }
   ],
   "source": [
    "# Generator architecture\n",
    "def build_generator(latent_dim, num_nodes):\n",
    "    input_layer = Input(shape=(latent_dim,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dense(num_nodes * num_nodes, activation='sigmoid')(x)  # Adjust output shape\n",
    "    generator = Model(input_layer, x)\n",
    "    return generator\n",
    "\n",
    "# Discriminator architecture\n",
    "def build_discriminator(num_nodes):\n",
    "    input_layer = Input(shape=(num_nodes * num_nodes,))\n",
    "    x = Dense(128)(input_layer)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(input_layer, output_layer)\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41731fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build and compile the generator and discriminator\n",
    "latent_dim = 32\n",
    "num_nodes = image_size * image_size\n",
    "generator = build_generator(latent_dim, num_nodes)\n",
    "discriminator = build_discriminator(num_nodes)\n",
    "\n",
    "generator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# The GAN architecture\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "generated_adj_matrices = generator(gan_input)\n",
    "gan_output = discriminator(generated_adj_matrices)\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for _ in range(num_images // batch_size):\n",
    "        idx = np.random.randint(0, num_images, batch_size)\n",
    "        real_adj_matrices = adj_matrices[idx]\n",
    "        latent_space_samples = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generated_adj_matrices = generator.predict(latent_space_samples)\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_adj_matrices.reshape((batch_size, num_nodes * num_nodes)), np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_adj_matrices, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        latent_space_samples = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(latent_space_samples, np.ones((batch_size, 1)))\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
