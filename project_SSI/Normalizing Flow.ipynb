{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9becf8a",
   "metadata": {},
   "source": [
    "**Task:-** \n",
    "\n",
    "EF-2: Try to make generative model of jet images, using a AUC of a discriminator to distinguish Generative model data / real data as metric\n",
    "\n",
    "From https://github.com/makagan/SSI_Projects/blob/main/jet_notebooks/1.LHCJetDatasetExploration.ipynbfrom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e73448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e2292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']\n"
     ]
    }
   ],
   "source": [
    " # Data already downloaded \n",
    "# let's open the file\n",
    "fileIN = '../jet_notebooks/Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5'\n",
    "f = h5py.File(fileIN)\n",
    "# and see what it contains\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fb77dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'j_ptfrac' b'j_pt' b'j_eta' b'j_mass' b'j_tau1_b1' b'j_tau2_b1'\n",
      " b'j_tau3_b1' b'j_tau1_b2' b'j_tau2_b2' b'j_tau3_b2' b'j_tau32_b1'\n",
      " b'j_tau32_b2' b'j_zlogz' b'j_c1_b0' b'j_c1_b1' b'j_c1_b2' b'j_c2_b1'\n",
      " b'j_c2_b2' b'j_d2_b1' b'j_d2_b2' b'j_d2_a1_b1' b'j_d2_a1_b2' b'j_m2_b1'\n",
      " b'j_m2_b2' b'j_n2_b1' b'j_n2_b2' b'j_tau1_b1_mmdt' b'j_tau2_b1_mmdt'\n",
      " b'j_tau3_b1_mmdt' b'j_tau1_b2_mmdt' b'j_tau2_b2_mmdt' b'j_tau3_b2_mmdt'\n",
      " b'j_tau32_b1_mmdt' b'j_tau32_b2_mmdt' b'j_c1_b0_mmdt' b'j_c1_b1_mmdt'\n",
      " b'j_c1_b2_mmdt' b'j_c2_b1_mmdt' b'j_c2_b2_mmdt' b'j_d2_b1_mmdt'\n",
      " b'j_d2_b2_mmdt' b'j_d2_a1_b1_mmdt' b'j_d2_a1_b2_mmdt' b'j_m2_b1_mmdt'\n",
      " b'j_m2_b2_mmdt' b'j_n2_b1_mmdt' b'j_n2_b2_mmdt' b'j_mass_trim'\n",
      " b'j_mass_mmdt' b'j_mass_prun' b'j_mass_sdb2' b'j_mass_sdm1'\n",
      " b'j_multiplicity' b'j_g' b'j_q' b'j_w' b'j_z' b'j_t' b'j_undef']\n"
     ]
    }
   ],
   "source": [
    "# These are the quantities we are dealing with\n",
    "featurenames = f.get('jetFeatureNames')\n",
    "print(featurenames[:])\n",
    "# the b is due to the byte vs utf-8 encoding of the strings in the dataset\n",
    "# just ignore them for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7592936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"jetImage\": shape (10000, 100, 100), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(f.get('jetImage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f94aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(10000, 5)\n",
      "First five entries:\n",
      "[1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0.]\n",
      "Last 5 entries:\n",
      "[0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "jet_data = np.array(f.get('jets'))\n",
    "target = jet_data[:,-6:-1]\n",
    "# shape of the dataset\n",
    "print(\"Dataset shape:\")\n",
    "print(target.shape)\n",
    "print(\"First five entries:\")\n",
    "for i in range(5):\n",
    "    print(target[i])\n",
    "print(\"Last 5 entries:\")\n",
    "for i in range(-5,0):\n",
    "    print(target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa02526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 53)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(jet_data[:,:-6])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4969dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = input_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index], 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)\n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41036653",
   "metadata": {},
   "source": [
    "# The particle-list dataset\n",
    "In this case, we look at the particle-related features that we have stored for each jet constituent. The structure of the dataset is similar to that of the physics-motivated features, except for the fact that we have now a double-index dataset: (jet index, particle index). The list is cut at 100 constituents /jet. If less are found, the dataset is completed filling it with 0s (zero padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca54a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'j1_px' b'j1_py' b'j1_pz' b'j1_e' b'j1_erel' b'j1_pt' b'j1_ptrel'\n",
      " b'j1_eta' b'j1_etarel' b'j1_etarot' b'j1_phi' b'j1_phirel' b'j1_phirot'\n",
      " b'j1_deltaR' b'j1_costheta' b'j1_costhetarel' b'j1_pdgid']\n"
     ]
    }
   ],
   "source": [
    "p_featurenames = f.get(\"particleFeatureNames\")\n",
    "print(p_featurenames[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c318ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "p_data = f.get(\"jetConstituentList\")\n",
    "print(p_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfa8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot_p(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        my_data = input_data[:,:,feature_index]\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = my_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index].flatten(), 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)  \n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324d8a4",
   "metadata": {},
   "source": [
    "## Generative model of jet images with AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b337846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing keras and related modules\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830ddffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664edb7",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess jet image data (replace with your own data loading)\n",
    "# Assuming you have jet images in a numpy array 'jet_images'\n",
    "jet_images = np.array(f.get('jetImage')).astype('float32') / 255.0\n",
    "num_images, image_size, _ = jet_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f255da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images and normalize pixel values\n",
    "flattened_images = jet_images.reshape(num_images, -1)\n",
    "flattened_images = (flattened_images - np.min(flattened_images)) / (np.max(flattened_images) - np.min(flattened_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bda6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple 2D Normalizing Flow model with fewer parameters\n",
    "\n",
    "# Define a simple transformation layer\n",
    "class TransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TransformationLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(TransformationLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mean = Dense(1, activation='linear')(inputs)\n",
    "        log_scale = Dense(1, activation='linear')(inputs)\n",
    "        scale = tf.exp(log_scale)\n",
    "        transformation = mean + scale * inputs\n",
    "        log_det_jacobian = tf.reduce_sum(log_scale, axis=1)\n",
    "        return transformation, log_det_jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41731fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Normalizing Flow model with multiple transformation layers\n",
    "input_layer = Input(shape=(flattened_images.shape[1],))\n",
    "x = input_layer\n",
    "num_layers = 3\n",
    "for _ in range(num_layers):\n",
    "    x, log_det_jacobian = TransformationLayer()(x)\n",
    "\n",
    "normalizing_flow_model = Model(input_layer, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964fca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory and resources\n",
    "tf.keras.backend.clear_session()\n",
    "# Explicitly set device\n",
    "with tf.device('/GPU:0'):  # Change to '/CPU:0' if needed\n",
    "    # Build the model\n",
    "    input_shape = (flattened_images.shape[1],)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Dense(32, activation='relu')(input_layer)\n",
    "    output_layer = Dense(input_shape[0], activation='linear')(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65446f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 02:02:26.570784: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 381.47MiB (rounded to 400000000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-08-16 02:02:26.570967: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *******************************************************************************************xxxxx****\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_2407469/25766403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos9-gcc11-opt/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos9-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(flattened_images, flattened_images, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples using the learned model\n",
    "samples = np.random.randn(num_images, flattened_images.shape[1])\n",
    "generated_samples = normalizing_flow_model.predict(samples)\n",
    "\n",
    "# Reshape generated samples back to image shape\n",
    "generated_images = generated_samples.reshape(num_images, image_size, image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated images\n",
    "for i in range(5):  # Display first 5 generated images\n",
    "    plt.imshow(generated_images[i], cmap='gray')\n",
    "    plt.title('Generated Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94112e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
