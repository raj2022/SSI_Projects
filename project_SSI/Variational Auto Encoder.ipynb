{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332b5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the files\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb8a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']\n"
     ]
    }
   ],
   "source": [
    " # Data already downloaded \n",
    "# let's open the file\n",
    "fileIN = '../jet_notebooks/Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5'\n",
    "f = h5py.File(fileIN)\n",
    "# and see what it contains\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "847b95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "# import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8781c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Assuming you have jet images in a numpy array 'jet_images'\n",
    "# Normalize the pixel values between 0 and 1\n",
    "jet_images = np.array(f.get('jetImage')).astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b432d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_size = int(0.8 * len(jet_images))\n",
    "x_train = jet_images[:train_size]\n",
    "x_val = jet_images[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d167b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87894659",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb086e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "          -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "    \n",
    "      This function computes the loss and gradients, and uses the latter to\n",
    "      update the model's parameters.\n",
    "      \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95e5b656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_examples_to_generate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m num_example_to_generate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# keeping the random vector constant for generation (prediction) so\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# it will be easier to see the improvement.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m random_vector_for_generation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[0;32m---> 10\u001b[0m     shape\u001b[38;5;241m=\u001b[39m[\u001b[43mnum_examples_to_generate\u001b[49m, latent_dim])\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m CVAE(latent_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_examples_to_generate' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Set the dimensionality of the latent space to a plane for visualization  later\n",
    "latent_dim = 2\n",
    "num_example_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b95d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c44d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a1d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your jet images dataset here\n",
    "# Prepare the data\n",
    "# Assuming you have jet images in a numpy array 'jet_images'\n",
    "# Normalize the pixel values between 0 and 1\n",
    "jet_images = np.array(f.get('jetImage')).astype('float32') / 255.0\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_size = int(0.8 * len(jet_images))\n",
    "x_train = jet_images[:train_size]\n",
    "x_val = jet_images[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2b0c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define other parameters\n",
    "image_size = jet_images.shape[1]\n",
    "latent_dim = 128\n",
    "epochs = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab388a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the VAE\n",
    "# Encoder\n",
    "input_img = Input(shape=(image_size, image_size))\n",
    "x = Flatten()(input_img)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0.0, stddev=1.0)\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "x = Dense(image_size * image_size, activation='relu')(decoder_input)\n",
    "decoded = Reshape((image_size, image_size))(x)\n",
    "\n",
    "# Create the decoder model\n",
    "decoder = Model(decoder_input, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09e6b4d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='input_20'), name='input_20', description=\"created by layer 'input_20'\") at layer \"dense_21\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the VAE model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vae \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\n\u001b[1;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/functional.py:266\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/functional.py:1142\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[0;32m-> 1142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following previous layers were accessed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1147\u001b[0m         )\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m   1149\u001b[0m     computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name='input_20'), name='input_20', description=\"created by layer 'input_20'\") at layer \"dense_21\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# Create the VAE model\n",
    "vae = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc2edd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def vae_loss(input_img, decoded):\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(input_img - decoded))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e61e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the decoder model with custom loss\n",
    "decoder.compile(optimizer='adam', loss=vae_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6c3bee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the decoder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m decoder\u001b[38;5;241m.\u001b[39mfit(\u001b[43mz_sampled\u001b[49m, jet_images, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_sampled' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the decoder\n",
    "decoder.fit(z_sampled, jet_images, epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204ecfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
