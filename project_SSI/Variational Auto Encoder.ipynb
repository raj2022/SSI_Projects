{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc0c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc547c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Data already downloaded \n",
    "# let's open the file\n",
    "fileIN = '../jet_notebooks/Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5'\n",
    "f = h5py.File(fileIN)\n",
    "# and see what it contains\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be42bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantities we are dealing with\n",
    "featurenames = f.get('jetFeatureNames')\n",
    "print(featurenames[:])\n",
    "# the b is due to the byte vs utf-8 encoding of the strings in the dataset\n",
    "# just ignore them for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.get('jetImage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data = np.array(f.get('jets'))\n",
    "target = jet_data[:,-6:-1]\n",
    "# shape of the dataset\n",
    "print(\"Dataset shape:\")\n",
    "print(target.shape)\n",
    "print(\"First five entries:\")\n",
    "for i in range(5):\n",
    "    print(target[i])\n",
    "print(\"Last 5 entries:\")\n",
    "for i in range(-5,0):\n",
    "    print(target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d09e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(jet_data[:,:-6])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = input_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index], 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)\n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21997828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now plot all the features\n",
    "for i in range(len(featurenames[:-6])):\n",
    "    makePlot(i, data, featurenames)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "image = np.array(f.get('jetImage'))\n",
    "image_g = image[np.argmax(target, axis=1) == 0]\n",
    "image_q = image[np.argmax(target, axis=1) == 1]\n",
    "image_W = image[np.argmax(target, axis=1) == 2]\n",
    "image_Z = image[np.argmax(target, axis=1) == 3]\n",
    "image_t = image[np.argmax(target, axis=1) == 4]\n",
    "images = [image_q, image_g, image_W, image_Z, image_t]\n",
    "#plt.rc('text', usetex=True) #you can uncomment this if you have a latex installation\n",
    "plt.rc('font', family='serif')\n",
    "for i in range(len(images)):\n",
    "    SUM_Image = np.sum(images[i], axis = 0)\n",
    "    plt.imshow(SUM_Image/float(images[i].shape[0]), origin='lower',norm=LogNorm(vmin=0.01))\n",
    "    plt.colorbar()\n",
    "    plt.title(labelCat[i], fontsize=15)\n",
    "    plt.xlabel(\"Delta_eta cell\", fontsize=15)\n",
    "    plt.ylabel(\"Delta_phi cell\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_featurenames = f.get(\"particleFeatureNames\")\n",
    "print(p_featurenames[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = f.get(\"jetConstituentList\")\n",
    "print(p_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78999d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "# this function makes the histogram of a given quantity for the five classes\n",
    "def makePlot_p(feature_index, input_data, input_featurenames):\n",
    "    plt.subplots()\n",
    "    for i in range(len(labelCat)):\n",
    "        my_data = input_data[:,:,feature_index]\n",
    "        # notice the use of numpy masking to select specific classes of jets\n",
    "        my_data = my_data[np.argmax(target, axis=1) == i]\n",
    "        # then plot the right quantity for the reduced array\n",
    "        plt.hist(my_data[:,feature_index].flatten(), 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
    "    plt.yscale('log')    \n",
    "    plt.legend(labelCat, fontsize=12, frameon=False)  \n",
    "    plt.xlabel(str(input_featurenames[feature_index], \"utf-8\"), fontsize=15)\n",
    "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
    "    plt.show()\n",
    "    #del fig, ax\n",
    "    #return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499539dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now plot all the features\n",
    "for i in range(len(p_featurenames)-1):\n",
    "    makePlot_p(i, p_data, p_featurenames)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b209295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing keras and related modules\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Lambda\n",
    "from tensorflow.keras.losses import mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Assuming you have jet images in a numpy array 'jet_images'\n",
    "# Normalize the pixel values between 0 and 1\n",
    "jet_images = np.array(f.get('jetImage')).astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the first image in the dataset\n",
    "first_image_shape = jet_images[0].shape\n",
    "\n",
    "# Print the dimensions of the first image\n",
    "print(\"Dimensions of the first image:\", first_image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d169a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shape = jet_images.shape\n",
    "# Print the shape of the dataset\n",
    "print(\"Shape of the dataset:\", dataset_shape)\n",
    "image_size = dataset_shape[1]\n",
    "print(f'image_size is,',image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_size = int(0.8 * len(jet_images))\n",
    "x_train = jet_images[:train_size]\n",
    "x_val = jet_images[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ef085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the batch dimension to your training and validation data\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # Add a single channel dimension\n",
    "x_val = np.expand_dims(x_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE architecture\n",
    "latent_dim = 2  # Dimension of latent space\n",
    "\n",
    "def build_vae(input_shape):\n",
    "    # Encoder\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "    \n",
    "    # Reparameterization trick\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = Model(encoder_input, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    # Decoder\n",
    "    latent_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(image_size // 4 * image_size // 4 * 64, activation='relu')(latent_input)\n",
    "    x = Reshape((image_size // 4, image_size // 4, 64))(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    decoder_output = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    decoder = Model(latent_input, decoder_output, name='decoder')\n",
    "    \n",
    "    # VAE model\n",
    "    _, _, encoded = encoder(encoder_input)\n",
    "    vae_output = decoder(encoded)\n",
    "    \n",
    "    vae = Model(encoder_input, vae_output, name='vae')\n",
    "    \n",
    "    # VAE loss\n",
    "    reconstruction_loss = mse(tf.reshape(encoder_input, [-1, image_size * image_size]), tf.reshape(vae_output, [-1, image_size * image_size]))\n",
    "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "    \n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    return vae, encoder, decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the jet images dataset to match the model's input shape\n",
    "jet_images_reshaped = jet_images.reshape((-1, image_size, image_size, 1))\n",
    "\n",
    "# Build and compile the VAE\n",
    "input_shape = jet_images_reshaped[0].shape\n",
    "vae, encoder, decoder = build_vae(input_shape)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "\n",
    "# ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bac3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "batch_size = 4  # Set the batch size based on dataset size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(jet_images_reshaped.shape[0] // batch_size):\n",
    "        batch_indices = np.random.randint(0, jet_images_reshaped.shape[0], batch_size)\n",
    "        batch = jet_images_reshaped[batch_indices]\n",
    "        vae.train_on_batch(batch, batch)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}, Loss: {vae.evaluate(jet_images_reshaped, jet_images_reshaped, verbose=0)}\")\n",
    "\n",
    "# Generate and save example images from the decoder\n",
    "num_examples = 10\n",
    "latent_samples = np.random.normal(size=(num_examples, latent_dim))\n",
    "generated_images = decoder.predict(latent_samples)\n",
    "\n",
    "# Display or save generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f34080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85889f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773f7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
